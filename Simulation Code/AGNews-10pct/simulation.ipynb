{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "jOtMRwLs9XAu"
      },
      "outputs": [],
      "source": [
        "\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from subprocess import check_output\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D,MaxPooling2D,Dense,Flatten,Dropout\n",
        "from tensorflow.keras.optimizers import Adam # - Works\n",
        "from keras.callbacks import TensorBoard\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix\n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import roc_auc_score, recall_score, f1_score\n",
        "import random\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "import seaborn as sns\n",
        "import time\n",
        "import math\n",
        "import numpy as np\n",
        "import collections\n",
        "import sys\n",
        "import os\n",
        "from simulation_random_single import simulate # import the simulation file\n",
        "\n",
        "dir_prefix = ''\n",
        "def split_to_int(myStr): # the function to convert the string of classes into an array with integers\n",
        "  return [int(char) for char in myStr]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vXBm1u7e9bAZ"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "\n",
        "####################  AGNews-10pct Model / data parameters  (No Change Here)  ####################\n",
        "#File Path\n",
        "TRAIN_FILE_PATH = \"agnews_10pct_data/train_10pct_new.csv\"\n",
        "TEST_FILE_PATH = \"agnews_10pct_data/test_10pct_new.csv\"\n",
        "\n",
        "\n",
        "#Load Data\n",
        "traindata = pd.read_csv(TRAIN_FILE_PATH, header=None)\n",
        "testdata = pd.read_csv(TEST_FILE_PATH, header=None)\n",
        "#Set Column Names \n",
        "traindata.columns = ['ClassIndex', 'Title', 'Description']\n",
        "testdata.columns = ['ClassIndex', 'Title', 'Description']#Combine Title and Description\n",
        "x_train = traindata['Title'] + \" \" + traindata['Description'] # Combine title and description (better accuracy than using them as separate features)\n",
        "y_train = traindata['ClassIndex'].apply(lambda x: x-1).values # Class labels need to begin from 0\n",
        "x_test = testdata['Title'] + \" \" + testdata['Description'] # Combine title and description (better accuracy than using them as separate features)\n",
        "y_test = testdata['ClassIndex'].apply(lambda x: x-1).values # Class labels need to begin from 0\n",
        "dataset = 'agnews_10pct'\n",
        "\n",
        "#Max Length of sentences in Train Dataset\n",
        "x_train = np.array(x_train)\n",
        "x_test = np.array(x_test)\n",
        "\n",
        "# #################### FashionMNIST Model / data parameters  (No Change Here)  ####################\n",
        "# input_shape = (28, 28, 1)\n",
        "# dataset = 'fashionMNIST'\n",
        "# # the data, split between train and test sets\n",
        "# (x_train, y_train), (x_test, y_test) = keras.datasets.fashion_mnist.load_data()\n",
        "# # Scale images to the [0, 1] range\n",
        "# x_train = x_train.astype(\"float32\") / 255\n",
        "# x_test = x_test.astype(\"float32\") / 255\n",
        "# # Make sure images have shape (28, 28, 1)\n",
        "# x_train = np.expand_dims(x_train, -1)\n",
        "# x_test = np.expand_dims(x_test, -1)\n",
        "# # print(\"x_train shape:\", x_train.shape)\n",
        "# # print(x_train.shape[0], \"train samples\")\n",
        "# # print(x_test.shape[0], \"test samples\")\n",
        "\n",
        "\n",
        "\n",
        "if not os.path.exists(dir_prefix + dataset + '_result/'):\n",
        "  os.makedirs(dir_prefix + dataset + '_result/')\n",
        "\n",
        "\n",
        "original_num_classes = len(np.unique(y_train))\n",
        "\n",
        "\n",
        "\n",
        "####################  Read the simulation parameters from the list of arguments  ####################\n",
        "ratio = 0.5\n",
        "model = 'mn'\n",
        "noise_type = 'uniform'  # Only ['uniform', 'locally-concentrated'] for num_classes = 2\n",
        "classesStr = '0123'\n",
        "good_user = True # Only simulate perfect\n",
        "percent_noise_list = [0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]\n",
        "frac = 0.1\n",
        "\n",
        "\n",
        "\n",
        "classes = split_to_int(classesStr)\n",
        "num_classes = len(classes)\n",
        "\n",
        "\n",
        "####################  Start the Simulation  ####################\n",
        "label_map = dict()     # encode the labels\n",
        "for i in range(0, len(classes)):\n",
        "  label_map[classes[i]] = i\n",
        "\n",
        "\n",
        "\n",
        "noise_ratio = ratio  # can be any number between 0-1\n",
        "noise_ratio_str = str(int(noise_ratio*100))\n",
        "if frac == 1:\n",
        "  fracStr = 'full'\n",
        "else: fracStr = 'frac' + str(frac)[-1]\n",
        "\n",
        "if num_classes == original_num_classes: classesStr = ''\n",
        "\n",
        "\n",
        "print(\"=========THIS ROUND: \", dataset, noise_type, noise_ratio)\n",
        "y_train_noisy_filepath = dir_prefix +  dataset + '_noisy_data/' + dataset + '_' + str(num_classes) + 'cls' + classesStr + '_' + fracStr + '_' + noise_type + '_' + noise_ratio_str + '.npy'\n",
        "\n",
        "y_train_noisy = np.load(y_train_noisy_filepath)\n",
        "\n",
        "sampled_idx_train_filepath = dir_prefix  + dataset + '_sampled_data/' + dataset + '_' + str(num_classes) + 'cls' + classesStr + '_train_' + fracStr + '_idx.npy'\n",
        "\n",
        "sampled_idx_train = np.load(sampled_idx_train_filepath)\n",
        "\n",
        "sampled_idx_test_filepath = dir_prefix  + dataset + '_sampled_data/' + dataset + '_' + str(num_classes) + 'cls' + classesStr + '_test_' + fracStr + '_idx.npy'\n",
        "\n",
        "sampled_idx_test = np.load(sampled_idx_test_filepath)\n",
        "\n",
        "x_train_sampled = x_train[sampled_idx_train]\n",
        "\n",
        "y_train_sampled = y_train[sampled_idx_train]\n",
        "\n",
        "x_test_sampled = x_test[sampled_idx_test]\n",
        "\n",
        "y_test_sampled = y_test[sampled_idx_test]\n",
        "\n",
        "\n",
        "\n",
        "# encode the clean y_train label\n",
        "for i in range(0, y_train_sampled.shape[0]):\n",
        "  prev_label = y_train_sampled[i]\n",
        "  # print('prev_label:', prev_label)\n",
        "  y_train_sampled[i] = label_map[prev_label]\n",
        "  # print('cur_label:', label_map[i]])\n",
        "for i in range(0, y_test_sampled.shape[0]):\n",
        "  prev_label = y_test_sampled[i]\n",
        "  y_test_sampled[i] = label_map[prev_label]\n",
        "\n",
        "\n",
        "\n",
        "user_str = ''\n",
        "if good_user: user_str = 'gooduser'\n",
        "\n",
        "\n",
        "############### Run the simulation and save result into a csv file  ###############\n",
        "exp_df, human_flip_err_df = simulate(dataset, x_train_sampled, y_train_noisy, x_test_sampled, y_test_sampled, y_train_sampled, noise_ratio, model, label_map.values(), good_user, percent_noise_list)\n",
        "exp_df.to_csv(dir_prefix + dataset + '_result/' + dataset+\"_\"+ model + \"_\" + noise_type +\"_\" + user_str + \"_random_\"+ str(num_classes) + 'cls' + classesStr + '_' + fracStr + '_' + noise_type + '_' + noise_ratio_str + \".csv\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "idQqhS6x9aSh"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O8jrvlSP9aU1"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N3jcxA4X9aXD"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X77L35N-9aZP"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XvWLGZHt9abZ"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LGJpE6Vs9adp"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MVqQcAmb9afj"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6oiAysTm9ahz"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
